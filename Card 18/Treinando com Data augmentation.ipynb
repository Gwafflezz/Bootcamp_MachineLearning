{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"elaT1Yo-x12A"},"outputs":[],"source":["from torchvision import datasets\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","data_folder = '/content'\n","fmnist = datasets.FashionMNIST(data_folder,\n","                              download=True,\n","                              train=True)\n","tr_images = fmnist.data\n","tr_targets = fmnist.targets\n","val_fmnist = datasets.FashionMNIST(data_folder,\n","                                  download=True,\n","                                  train=True)\n","tr_images = fmnist.data\n","tr_targets = fmnist.targets\n","val_fmnist = datasets.FashionMNIST(data_folder,\n","                                   download=True,\n","                                   train=False)\n","val_images = val_fmnist.data\n","val_targets = val_fmnist.targets\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jlEXa0x651b"},"outputs":[],"source":["from imgaug import augmenters as iaa\n","aug = iaa.Sequential([\n","    iaa.Affine(translate_px={'x':(-10,10)},\n","        mode='constant'),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s3qJPHvB8iST"},"outputs":[],"source":["class FMNISTDataset(Dataset):\n","    def __init__(self, x, y, aug=None):\n","        self.x, self.y = x, y\n","        self.aug = aug\n","    def __getitem__(self, ix):\n","        x, y = self.x[ix], self.y[ix]\n","        return x, y\n","    def __len__(self): return len(self.x)\n","\n","    def collate_fn(self, batch):\n","        'logic to modify a batch of images'\n","        ims, classes = list(zip(*batch))\n","        if self.aug:\n","          ims_np = np.array([tensor.numpy() for tensor in ims])\n","          ims=self.aug.augment_images(images=ims_np)\n","\n","        ims = torch.tensor(ims)[:,None,:,:].to(device)/255.\n","        classes = torch.tensor(classes).to(device)\n","        return ims, classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bhPTCp9m-vW1"},"outputs":[],"source":["from torch.optim import SGD, Adam\n","def get_model():\n","    model = nn.Sequential(\n","        nn.Conv2d(1, 64, kernel_size=3),\n","        nn.MaxPool2d(2),\n","        nn.ReLU(),\n","        nn.Conv2d(64, 128, kernel_size=3),\n","        nn.MaxPool2d(2),\n","        nn.ReLU(),\n","        nn.Flatten(),\n","        nn.Linear(3200, 256),\n","        nn.ReLU(),\n","        nn.Linear(256, 10)\n","    ).to(device)\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=1e-3)\n","    return model, loss_fn, optimizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UaH5tnBjHwkQ"},"outputs":[],"source":["def train_batch(x, y, model, opt, loss_fn):\n","    model.train()\n","    prediction = model(x)\n","    batch_loss = loss_fn(prediction, y)\n","    batch_loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","    return batch_loss.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NTDzwpIsIRHD"},"outputs":[],"source":["def get_data():\n","    train = FMNISTDataset(tr_images, tr_targets, aug=aug)\n","    trn_dl = DataLoader(train, batch_size=64,\n","                collate_fn=train.collate_fn, shuffle=True)\n","    val = FMNISTDataset(val_images, val_targets)\n","    val_dl = DataLoader(val, batch_size=len(val_images),\n","                collate_fn=val.collate_fn, shuffle=True)\n","    return trn_dl, val_dl"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WJ3x10fBJY-K","outputId":"a2aa3310-c8cb-491b-fc81-718d84732fad"},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n"]}],"source":["trn_dl, val_dl = get_data()\n","model, loss_fn, optimizer = get_model()\n","for epoch in range(5):\n","    print(epoch)\n","    for ix, batch in enumerate(iter(trn_dl)):\n","        x, y = batch\n","        batch_loss = train_batch(x, y, model, optimizer, loss_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qunT7LUNWT-"},"outputs":[],"source":["m#melhores predi√ßoes\n","preds = []\n","ix = 24300\n","for px in range(-5,6):\n","    img = tr_images[ix]/255.\n","    img = img.view(28, 28)\n","    img2 = np.roll(img, px, axis=1)\n","    img3 = torch.Tensor(img2).view(-1,1,28,28).to(device)\n","    np_output = model(img3).cpu().detach().numpy()\n","    pred = np.exp(np_output)/np.sum(np.exp(np_output))\n","    preds.append(pred)\n","    plt.imshow(img2)\n","    plt.title(fmnist.classes[pred[0].argmax()])\n","    plt.show()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOyLwfutrWB752QzC/fHsd+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}